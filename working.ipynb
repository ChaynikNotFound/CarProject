{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66428e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU: 12\n",
      "RAM GB: 15.8\n",
      "PyTorch version: 2.1.0+cpu\n",
      "CUDA version: None\n",
      "cuDNN version: None\n",
      "device: cpu\n",
      "Sun Oct 29 17:28:23 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 442.23       Driver Version: 442.23       CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 166... WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   61C    P0    27W /  N/A |    154MiB /  6144MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0      4088      C   ...n\\NVIDIA RTX Voice\\NVIDIA RTX Voice.exe N/A      |\n",
      "|    0     12932    C+G   ...ogram Files (x86)\\Overwolf\\Overwolf.exe N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import torch\n",
    "from psutil import virtual_memory\n",
    "\n",
    "ram_gb = round(virtual_memory().total / 1024**3, 1)\n",
    "\n",
    "print('CPU:', multiprocessing.cpu_count())\n",
    "print('RAM GB:', ram_gb)\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "print(\"cuDNN version:\", torch.backends.cudnn.version())\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device.type)\n",
    "\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7918e8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install git+https://github.com/cene555/ru-clip-tiny.git\n",
    "!gdown -O ru-clip-tiny.pkl https://drive.google.com/uc?id=1-3g3J90pZmHo9jbBzsEmr7ei5zm3VXOL\n",
    "!gdown -O cifar100classes.json https://drive.google.com/uc?id=1ZJhOp5RP5wY31TyJgGNXa9xaJO8SdAhf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9dcf270c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "import transformers\n",
    "from transformers import BertTokenizer\n",
    "from rucliptiny import RuCLIPtiny\n",
    "from predictor import Predictor\n",
    "from PIL import ImageCms\n",
    "from utils import get_transform\n",
    "from tokenizer import Tokenizer\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb2103c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e4b01fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def speed_test(func, data_gen, n=5, empty_cache=True, is_text=False):\n",
    "    if empty_cache: torch.cuda.empty_cache()\n",
    "    values = []\n",
    "    for _ in range(n):\n",
    "        if is_text:\n",
    "            input_data1, input_data2 = data_gen()\n",
    "        else:\n",
    "            input_data = data_gen()\n",
    "        t = time.time()\n",
    "        if is_text:\n",
    "            func(input_data1, input_data2)\n",
    "        else:\n",
    "            func(input_data)\n",
    "        values.append(time.time() - t)\n",
    "        if empty_cache: torch.cuda.empty_cache()\n",
    "    return sum(values) / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2a0933e5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "\n",
    "\n",
    "# def prepare_classes(classes):\n",
    "#     return [f\"{label.lower()}\" for label in classes]\n",
    "\n",
    "\n",
    "# def get_text_probs_from_dataset(\n",
    "#         model,\n",
    "#         tokenizer=None,\n",
    "#         ds=None,\n",
    "#         train=False,\n",
    "#         classes_path=None,\n",
    "#         text_descriptions=None,\n",
    "#         transform=None\n",
    "# ):\n",
    "#     if ds is None:\n",
    "#         cls = CIFAR100\n",
    "#         ds = cls(os.path.expanduser(\"~/.cache\"), download=True, train=train)\n",
    "#         if classes_path is None:\n",
    "#             classes_path = f\"../clip/evaluate/{name.lower()}/{name.lower()}classes.json\"\n",
    "#         with open(classes_path, \"r\") as file:\n",
    "#             ds.classes = json.load(file)\n",
    "#     if text_descriptions is None:\n",
    "#         text_descriptions = prepare_classes(ds.classes)\n",
    "#     text_input = tokenizer.tokenize(text_descriptions).to(device)\n",
    "#     probs = []\n",
    "#     labels = []\n",
    "#     with torch.no_grad():\n",
    "#         text_features = model.encode_text(text_input[0], text_input[1]).float()\n",
    "#         text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "#         for x in tqdm(ds, total=len(ds)):\n",
    "#             images = [transform(x[0])]\n",
    "#             image_features = model.encode_image(torch.stack(images).to(device)).float()\n",
    "#             image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "#             text_probs = (1 * image_features @ text_features.T).softmax(dim=-1)\n",
    "#             labels.append(x[1])\n",
    "#             probs.append(text_probs.tolist()[0])\n",
    "#     return probs, labels\n",
    "\n",
    "\n",
    "\n",
    "root_f = \"C:/Users/User/anaconda3/NEURO/cars/car_data/train\"\n",
    "\n",
    "carbase = pd.DataFrame(columns=['Cars', 'Pictures'])\n",
    "for f in os.listdir(root_f):\n",
    "    folders = os.path.normpath(os.path.join(root_f, f))\n",
    "    \n",
    "    #print(f)\n",
    "    file_paths = ''\n",
    "    pictures = os.listdir(folders)\n",
    "    data=''\n",
    "    for p in pictures:\n",
    "        file_path = os.path.normpath(os.path.join(folders, p))\n",
    "        data+=file_path\n",
    "        data+=','\n",
    "    carbase.loc[len(carbase)] = [f, data]\n",
    "\n",
    "carbase.to_csv('carbase.csv', index=False)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "# def get_topk_accuracy(labels, probs, k=5):\n",
    "#     successes = 0\n",
    "#     for lbl, p in zip(labels, np.array(probs)):\n",
    "#         _, top_labels = torch.tensor(p).topk(k, dim=-1)\n",
    "#         if lbl in top_labels:\n",
    "#             successes += 1\n",
    "#     return successes / len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4718d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b72aeb8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d6141f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
